# Directories to scan
scan_directories = [
    "dir1",
    "dir2",
    # ...
    "dirN",
]

# File and directories matching the patterns below will be excluded
exclusion_patterns = [
    "\\.(hpp|txt|log|cmake|json)$", # extensions defined with a single expression
    "\\.cache",
    "\\.cargo",
    "\\.config",
    "\\.dups_cache",
    "\\.git",
    "\\.local",
    "\\.vscode",
    "build",
    "snap"
]

# Patterns of the paths considered safe for deletion.
# If a file is in the path, it will be considered safe for deletion.
# The application will produce a warning when the all files in the duplicate group are
# located in one of these paths
safe_for_deletion_paths = [
    "/pattern/of/the/path/considered/safe/for/deletion"
]

# Ignore files smaller then this
min_file_size_bytes = 1024

# Ignore files larger then this (10 Gb)
max_file_size_bytes = 10737418240

# Frequency of the duplicate detection updates, it controls how frequently the application
# should report about the detection progress. Value 0 disables updates
update_freq_ms = 100

# Cache directory. Application will maintain cache to quickly fetch information about
# files which are already scanned
cache_directory = ".dups_cache"

# File to dump paths of all scanned files
all_files = "files.txt"

# File to dump the duplicates
dup_files = "dups.txt"

